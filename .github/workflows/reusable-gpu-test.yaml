
name: Reusable OpenMM GPU Test
on:
  workflow_call:
    inputs:
      instance_type: # The EC2 instance type needed
        required: true
        type: string
jobs:
  ec2:
    runs-on: ubuntu-latest
    outputs:
      mapping: ${{ steps.aws-start.outputs.mapping }}
      instances: ${{ steps.aws-start.outputs.instances }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE }}
          aws-region: us-east-1
      - name: Create cloud runner
        id: aws-start
        uses: Open-Athena/ec2-gha@rw/hooks
        with:
          aws_region: us-east-1
          ec2_image_id: ami-0f7c4a792e3fb63c8
          ec2_instance_type: ${{ inputs.instance_type }}
          ec2_home_dir: /home/ubuntu
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
  openmm-test:
    needs: ec2
    runs-on: ${{ needs.ec2.outputs.id }}
    defaults:
      run:
        shell: bash -leo pipefail {0}
    steps:
      - uses: actions/checkout@v4
      - name: Print disk usage
        run: "df -h"
      - name: Print Docker details
        run: "docker version || true"
      - name: Check for nvidia-smi
        run: "nvidia-smi || true"
      - uses: mamba-org/setup-micromamba@main
        with:
          environment-name: openmm
          create-args: >-
            openmm
          condarc: |
            channels:
              - conda-forge
      - name: Test for GPU
        id: gpu_test
        run: python -m openmm.testInstallation
